---
title: "Authenticity and AI"
description: "Thoughts on the changing landscape of AI and how it's impacting our lives"
tags: ['ai', 'life', 'agents']
publishedAt: "20 July 2025"
---

I've been thinking about authenticity lately. Not in a philosophical way, but in the everyday sense of knowing when something is someone's own work versus when it's been AI generated.

This definitely isn't a new problem, but it's becoming more common and blatantly obvious at times. People are using AI to write their social media posts, blog articles (wouldn't it be ironic?), especially professional content, and presenting it as their own original thoughts/work. It's cultivated a landscape where you unsure if you can trust what you're reading actually came from the person who posted it. Half the time it seems as though the person hasn't even gone to the effort of proof reading it??

The irony for me, in being a programmer, is that AI is actually helping maintain authenticity, not eroding it (outside of the context of content creation, which I don't really do beyond these thought posts once a blue moon)

## The Programming Paradox (or something like that?)

I've been using Claude a lot when working on repos I'm not familiar with at work. And also in ones that I'm in daily. The thing that strikes me most when using it is how well it picks up on existing patterns when you guide it properly. It more often than not doesn't impose generic "AI" coding style – it adapts to what's already there, sometimes requiring a bit of guidance at first. I begun on my current codebase at work when it was (in my opinion, shock horror) in a dire state with no governance or consistent conventions. Claude at that time was causing mayhem. As the codebase has become more polished, with clear opinions defined, his ability to output work effectively (and without me losing my hair), has significantly increased. And I'm not the only person to share this opinion in the team.

If the team uses specific naming conventions, Claude follows them. If there's a particular way we structure components or handle error cases, it catches on and maintains that consistency. It's often like having a really good pair programmer who takes the time to understand the team's established practices before contributing, but with the ability to absorb thousands of lines of code in minutes.

In established teams, or even fairly new ones as we are at Saber currently, this turns out to be incredibly valuable. Instead of having to constantly remind people about code standards during reviews, the AI helps enforce them naturally. It spots the patterns that define the team's authentic coding voice and keeps them intact. This factor is only further enhanced when using the new skills, or even a basic AGENTS.md file.

## Two Sides of the Same Tool

The contrast to me is pretty stark. For content creation, AI strips away quirks and inconsistencies that make someone's writing *actually* theirs. But in programming, those same capabilities support in preserving the collective voice of a development team.

AI-generated blog posts passed off as original work feel like we're losing something important – the messy, imperfect, and human way of thinking/working. But when I see it help maintain coding standards across a team, it feels as though we're preserving something valuable about how that group works together.

Maybe the thought that floats in my mind as a question isn't whether AI is making stuff less authentic, but whether we're understanding the role it's having. There's bound to be a difference between using it as a tool to help you express your ideas more clearly, or to solve problems effectively, and using it to generate ideas that you then pass off as your own.

Ultimately I'm attempting to be thoughtful about when and how I use AI in my daily life. In coding, I've found it genuinely helpful, and the speed of my work has shifted upwards incredibly. Beyond that? Gemini's great for generating meme photos of my friends, I'll stick to that.
